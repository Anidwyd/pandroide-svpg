{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfGJCe52lP4"
      },
      "source": [
        "# Outlook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZUSf0n_2otG"
      },
      "source": [
        "In this colab we give a detailed documentation of a version of the A2C algorithm using SaLinA, so as to better understand the inner mechanisms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHO1nIdM21Lq"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymc-lbXi9vDE"
      },
      "source": [
        "The SaLinA library is [here](https://github.com/facebookresearch/salina)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqBhIAjq23Vs"
      },
      "source": [
        "Note the trick: we first try to import, if it fails we install the github repository and import again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j0MaggiOl4KU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym==0.21.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (0.21.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from gym==0.21.0) (4.11.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from gym==0.21.0) (1.21.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from gym==0.21.0) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym==0.21.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym==0.21.0) (3.7.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting git+https://github.com/facebookresearch/salina.git@main\n",
            "  Cloning https://github.com/facebookresearch/salina.git (to revision main) to /tmp/pip-req-build-v93tlwek\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/salina.git /tmp/pip-req-build-v93tlwek\n",
            "  Resolved https://github.com/facebookresearch/salina.git to commit 748b11563e5bea2c4a50d1043b6cfdf238d49664\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (1.10.2)\n",
            "Requirement already satisfied: torchvision in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (0.11.3)\n",
            "Requirement already satisfied: gym>=0.21.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (0.21.0)\n",
            "Requirement already satisfied: tensorboard in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (4.62.3)\n",
            "Requirement already satisfied: hydra-core in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (1.1.1)\n",
            "Requirement already satisfied: numpy in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (1.21.5)\n",
            "Requirement already satisfied: pandas in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (1.3.5)\n",
            "Requirement already satisfied: opencv-python in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (4.5.5.62)\n",
            "Requirement already satisfied: pygame in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (2.1.2)\n",
            "Requirement already satisfied: xformers>=0.0.3 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from salina==1.0) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from gym>=0.21.0->salina==1.0) (4.11.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from gym>=0.21.0->salina==1.0) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from torch>=1.9.0->salina==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyre-extensions==0.0.23 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from xformers>=0.0.3->salina==1.0) (0.0.23)\n",
            "Requirement already satisfied: typing-inspect in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from pyre-extensions==0.0.23->xformers>=0.0.3->salina==1.0) (0.7.1)\n",
            "Requirement already satisfied: importlib-resources in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from hydra-core->salina==1.0) (5.4.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from hydra-core->salina==1.0) (4.8)\n",
            "Requirement already satisfied: omegaconf==2.1.* in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from hydra-core->salina==1.0) (2.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from omegaconf==2.1.*->hydra-core->salina==1.0) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from pandas->salina==1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from pandas->salina==1.0) (2021.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (2.6.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (0.6.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (60.9.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (2.0.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (3.19.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard->salina==1.0) (1.44.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from torchvision->salina==1.0) (9.0.1)\n",
            "Requirement already satisfied: six in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard->salina==1.0) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->salina==1.0) (0.2.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->salina==1.0) (4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->salina==1.0) (5.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->salina==1.0) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym>=0.21.0->salina==1.0) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->salina==1.0) (1.26.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->salina==1.0) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->salina==1.0) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->salina==1.0) (2.0.12)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->salina==1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->salina==1.0) (3.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (from typing-inspect->pyre-extensions==0.0.23->xformers>=0.0.3->salina==1.0) (0.4.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pygame in /home/khiemlk17/anaconda3/envs/ml/lib/python3.7/site-packages (2.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import functools\n",
        "import time\n",
        "\n",
        "%pip install gym==0.21.0\n",
        "%pip install git+https://github.com/facebookresearch/salina.git@main\n",
        "%pip install pygame\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Anidwyd/pandroide-svpg.git@main\n",
            "  Cloning https://github.com/Anidwyd/pandroide-svpg.git (to revision main) to /tmp/pip-req-build-vexyb648\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Anidwyd/pandroide-svpg.git /tmp/pip-req-build-vexyb648\n",
            "  Resolved https://github.com/Anidwyd/pandroide-svpg.git to commit 99cd1106bf51f00764e5b6399984e01032c79395\n",
            "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 36, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-req-build-vexyb648/setup.py\", line 17, in <module>\n",
            "  \u001b[31m   \u001b[0m     long_description=read('README')\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-req-build-vexyb648/setup.py\", line 9, in read\n",
            "  \u001b[31m   \u001b[0m     return open(os.path.join(os.path.dirname(__file__), fname)).read()\n",
            "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-req-build-vexyb648/README'\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/Anidwyd/pandroide-svpg.git@main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4kV9pWV3wRe"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caqhJYbe5YcO"
      },
      "source": [
        "Below, we import standard python packages, pytorch packages, hydra and gym environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0m4MzC5zlH"
      },
      "source": [
        "According to [the documentation](https://hydra.cc/docs/intro/) \"Hydra is an open-source Python framework (from facebook research, NDLR) that simplifies the development of research and other complex applications. The key feature is the ability to dynamically create a hierarchical configuration by composition and override it through config files and the command line. The name Hydra comes from its ability to run multiple similar jobs - much like a Hydra with multiple heads.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDy9yuQH73tJ"
      },
      "source": [
        "This is hydra that makes it possible that by just defining the `def run_a2c(cfg):` function and then executing a long `params = {...}` variable at the bottom of this colab, the code is run with the parameters without calling an explicit main."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niMWIw9cR-MI"
      },
      "source": [
        "More precisely, the code is run by calling\n",
        "\n",
        "`from omegaconf import DictConfig, OmegaConf`\n",
        "\n",
        "`config=OmegaConf.create(params)`\n",
        "\n",
        "`run_a2c(config)`\n",
        "\n",
        "at the very bottom of the colab, after starting tensorboard.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KENzsgMkkRH5"
      },
      "source": [
        "In fact, Hydra can do many more things for you, such as launching many jobs on a cluster each with its own configuration (agent, environment, CPU or GPU, etc.). It also provides a mechanism to instantiate classes and functions as parameters, which makes your program more flexible. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l7sTVXbJBE_"
      },
      "source": [
        "[OpenAI gym](https://gym.openai.com/) is a collection of benchmark environments to evaluate RL algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vktQB-AO5biu"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import hydra\n",
        "\n",
        "import gym\n",
        "# The TimeLimit wrapper is useful to specify a max number of steps for an RL episode\n",
        "from gym.wrappers import TimeLimit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE1c7ZLf60X_"
      },
      "source": [
        "### SaLinA imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ba3usKT9VrF"
      },
      "source": [
        "As explained in [the white paper](https://arxiv.org/pdf/2110.07910.pdf), everything in SaLinA is an Agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcYel28xAWOF"
      },
      "source": [
        "This construct is defined in [the salina/agent.py](https://github.com/facebookresearch/salina/blob/main/salina/agent.py) file as the Agent class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDF4Y3a8Aw8b"
      },
      "source": [
        "In practice, in RL one should rather use `TAgents`, that is agents that use a time index in their `__call__` function. But this is an abstract class, which only adds an abstraction layer for not much, so Ludovic Denoyer rather advises to directly use the `Agent` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfCZrhKV_PPr"
      },
      "source": [
        "Some of the comments below are just copy-pasted from the paper or from the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcuqoAvG3zMZ"
      },
      "outputs": [],
      "source": [
        "import salina\n",
        "\n",
        "# Following Ludovic Denoyer's advice, we use Agent rather than TAgent\n",
        "# `TAgent` is used as a convention \n",
        "# to represent agents that use a time index in their `__call__` function (not mandatory)\n",
        "from salina import Agent, get_arguments, get_class, instantiate_class\n",
        "\n",
        "# Agents(agent1,agent2,agent3,...) executes the different agents the one after the other\n",
        "# TemporalAgent(agent) executes an agent (e.g a TAgent) over multiple timesteps in the workspace, \n",
        "# or until a given condition is reached\n",
        "from salina.agents import Agents, RemoteAgent, TemporalAgent\n",
        "\n",
        "# GymAgent (resp. AutoResetGymAgent) are agents able to execute a batch of gym environments\n",
        "# without (resp. with) auto-resetting. These agents produce multiple variables in the workspace: \n",
        "# ’env/env_obs’, ’env/reward’, ’env/timestep’, ’env/done’, ’env/initial_state’, ’env/cumulated_reward’, \n",
        "# ... When called at timestep t=0, then the environments are automatically reset. \n",
        "# At timestep t>0, these agents will read the ’action’ variable in the workspace at time t − 1\n",
        "from salina.agents.gyma import AutoResetGymAgent, GymAgent\n",
        "\n",
        "# Not present in the A2C version...\n",
        "from salina.logger import TFLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHWdBJq58wKC"
      },
      "source": [
        "### Helper function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDOCUQoP86Ue"
      },
      "source": [
        "The function below is used below in the following piece of code later at the bottom of this colab:\n",
        "\n",
        "`# Compute A2C loss`\n",
        "\n",
        "`action_logp = _index(action_probs, action).log()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14gQa69xBRDR"
      },
      "source": [
        "It is used to transform the TxBxA action log probabilities matrix with a TxB index matrix to a TxB matrix where we have selected the log prob of the action taken by the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuKe5X2V7BA4"
      },
      "outputs": [],
      "source": [
        "def _index(tensor_3d, tensor_2d):\n",
        "    \"\"\"This function is used to index a 3d tensors using a 2d tensor\"\"\"\n",
        "    x, y, z = tensor_3d.size()\n",
        "    t = tensor_3d.reshape(x * y, z)\n",
        "    tt = tensor_2d.reshape(x * y)\n",
        "    v = t[torch.arange(x * y), tt]\n",
        "    v = v.reshape(x, y)\n",
        "    return v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVvAfhKm9S8p"
      },
      "source": [
        "## Definition of agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdqzKSLKDtqz"
      },
      "source": [
        "The [A2C](http://proceedings.mlr.press/v48/mniha16.pdf) algorithm is an actor-critic algorithm. Thus we need an Actor agent and a Critic agent. \n",
        "The actor agent is built on an intermediate ProbAgent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piMBip8cBc5H"
      },
      "source": [
        "As explained above, in principle all agents should be built on the TAgent class, which itself inherits from the Agent class. In practice, TAgent is still in Salina for historical reasons, just using Agent simplifies the understanding. A TAgent is just an Agent with a 't' argument in the forward function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPNPS9LsC5on"
      },
      "source": [
        "### ProbAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic-54dzcBvwE"
      },
      "source": [
        "A ProbAgent is a one hidden layer neural network which takes an observation as input and whose output is a probability given by a final softmax layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73osLT0YCcys"
      },
      "source": [
        "Note that to get the input observation from the environment we call\n",
        "\n",
        "`observation = self.get((\"env/env_obs\", t))`\n",
        "\n",
        "and that to perform an action in the environment we call\n",
        "\n",
        "`self.set((\"action_probs\", t), probs)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe2thODO7E40"
      },
      "outputs": [],
      "source": [
        "class ProbAgent(Agent):\n",
        "    def __init__(self, observation_size, hidden_size, n_actions):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(observation_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions),\n",
        "        )\n",
        "\n",
        "    def forward(self, t, **kwargs):\n",
        "        observation = self.get((\"env/env_obs\", t))\n",
        "        scores = self.model(observation)\n",
        "        probs = torch.softmax(scores, dim=-1)\n",
        "        self.set((\"action_probs\", t), probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47_vBu8aC9hU"
      },
      "source": [
        "### ActionAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNlmjpg5DJEY"
      },
      "source": [
        "The ActionAgent takes action probabilities as input (coming from the ProbAgent) and outputs an action. In the deterministic case it takes the argmax, in the stochastic case it samples from the Categorical distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARPW1Mmo7NB-"
      },
      "outputs": [],
      "source": [
        "class ActionAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, t, stochastic, **kwargs):\n",
        "        probs = self.get((\"action_probs\", t))\n",
        "        if stochastic:\n",
        "            action = torch.distributions.Categorical(probs).sample()\n",
        "        else:\n",
        "            action = probs.argmax(1)\n",
        "\n",
        "        self.set((\"action\", t), action)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Din6iU-1DnyH"
      },
      "source": [
        "### CriticAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf0mXQvbEw7V"
      },
      "source": [
        "A CriticAgent is a one hidden layer neural network which takes an observation as input and whose output is the value of this observation. It thus implements a $V(s)$ function. It would be straightforward to define another CriticAgent (call it a CriticQAgent by contrast to a CriticVAgent) that would take an observation and an action as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQLc3dywFiqy"
      },
      "source": [
        "TODO: explain why we need the `squeeze(-1)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8y-63nq7Pjo"
      },
      "outputs": [],
      "source": [
        "class CriticAgent(Agent):\n",
        "    def __init__(self, observation_size, hidden_size, n_actions):\n",
        "        super().__init__()\n",
        "        self.critic_model = nn.Sequential(\n",
        "            nn.Linear(observation_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, t, **kwargs):\n",
        "        observation = self.get((\"env/env_obs\", t))\n",
        "        critic = self.critic_model(observation).squeeze(-1)\n",
        "        self.set((\"critic\", t), critic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01yjyr34OU4-"
      },
      "source": [
        "## Create the environment agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHaRqpSAGYDL"
      },
      "source": [
        "### Using a gym environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-7OSw9BGb7t"
      },
      "source": [
        "The function below is used in the params section at the bottom of the colab with `\"env\":{\n",
        "      \"classname\": \"__main__.make_env\",\n",
        "      \"env_name\": \"CartPole-v0\",\n",
        "      \"max_episode_steps\": 100,\n",
        "    },`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTu5J850GpyI"
      },
      "source": [
        "Using this instantiation approach from a function is useful if you define a new env for instance i.e you just change the 'classname' and put the arguments of the constructor directly and everything will work fine. This may be not natural a first sight, but if you start to use it, you will never go back again :) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsb5QRzw7V0o"
      },
      "outputs": [],
      "source": [
        "def make_env(env_name, max_episode_steps):\n",
        "    return TimeLimit(gym.make(env_name), max_episode_steps=max_episode_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KQXtTT0StIX"
      },
      "source": [
        "The `instantiate_class`, `get_class` and `get_arguments` functions are available in the [main/salina/__init__.py file](https://github.com/facebookresearch/salina/blob/main/salina/__init__.py). The `get_class` function reads the `classname` in the parameters to create the appropriate type of object, and the `get_arguments` function reads the local paremeters and their values to set them into the corresponding object. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P41ig0ciljqf"
      },
      "source": [
        "Note that in practice Hydra provides the same mechanisms, so the Hydra `instantiate` function could have been used instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODluTUN5L7jn"
      },
      "outputs": [],
      "source": [
        "class EnvAgent(GymAgent):\n",
        "  # Create the environment agent\n",
        "  # This agent implements N gym environments with auto-reset\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__(\n",
        "      get_class(cfg.algorithm.env),\n",
        "      get_arguments(cfg.algorithm.env),\n",
        "      n_envs=cfg.algorithm.n_envs,\n",
        "    )\n",
        "    self.env = instantiate_class(cfg.algorithm.env)\n",
        "\n",
        "  # TODO: replace the code below by a unique context-sensitive function \n",
        "  # that returns self.action_space.shape[0] or self.action_space.n\n",
        "  # depending on whether the action space is a Box or a Discrete space\n",
        "\n",
        "\n",
        "  # This is necessary to create the corresponding RL agent\n",
        "  def get_obs_and_actions_sizes(self):\n",
        "    if self.action_space.isinstance(gym.spaces.Box):\n",
        "        # Return the size of the observation and action spaces of the environment\n",
        "        # In the case of a continuous action environment\n",
        "        return self.observation_space.shape[0], self.action_space.shape[0]\n",
        "    elif self.action_space.isinstance(gym.spaces.Discrete):\n",
        "        # Return the size of the observation and action spaces of the environment\n",
        "      return self.observation_space.shape[0], self.action_space.n\n",
        "    else:\n",
        "      print (\"unknown type of action space\", self.action_space)\n",
        "      return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzxoIPtLVJ_i"
      },
      "source": [
        "### Create the A2C agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ0qhRVgVarb"
      },
      "source": [
        "The code below is rather straightforward. Note that we have not defined anything about data collection, using a RolloutBuffer or something to store the n_step return so far. This will come inside the training loop below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaNnZw3bXEYd"
      },
      "source": [
        "Interestingly, the loop between the policy and the environment is first defined as a collection of agents, and then embedeed into a single TemporalAgent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kj9y1hjVrXi"
      },
      "source": [
        "We delete the environment (not the environment agent) with `del env_agent.env` once we do not need it anymore just to avoid mistakes afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8Uk_RQh8QrO"
      },
      "outputs": [],
      "source": [
        "# Create the A2C Agent\n",
        "def create_a2c_agent(cfg, env_agent):\n",
        "  observation_size,  n_actions = env_agent.get_obs_and_actions_sizes()\n",
        "  del env_agent.env\n",
        "  prob_agent = ProbAgent(\n",
        "      observation_size, cfg.algorithm.architecture.hidden_size, n_actions\n",
        "  )\n",
        "  action_agent = ActionAgent()\n",
        "  critic_agent = CriticAgent(\n",
        "    observation_size, cfg.algorithm.architecture.hidden_size, n_actions\n",
        "  )\n",
        "\n",
        "  # Combine env and policy agents\n",
        "  agent = Agents(env_agent, prob_agent, action_agent)\n",
        "  # Get an agent that is executed on a complete workspace\n",
        "  agent = TemporalAgent(agent)\n",
        "  agent.seed(cfg.algorithm.env_seed)\n",
        "  return agent, prob_agent, critic_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU3cO6znHyDc"
      },
      "source": [
        "### The Logger class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4BrXwTLdK0Z"
      },
      "source": [
        "The logger class below is not generic, it is specifically designed in the context of this A2C colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKYYp8IHLhd-"
      },
      "source": [
        "The logger parameters are defined below in `params = { \"logger\":{ ...`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhwNN4oCNOhi"
      },
      "source": [
        "In this colab, the logger is defined as `salina.logger.TFLogger` so as to use a tensorboard visualisation (see the parameters part below).\n",
        "Note that the salina Logger is also saving the log in a readable format such that you can use `Logger.read_directories(...)` to read multiple logs, create a dataframe, and analyze many experiments afterward in a notebook for instance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10TUc-PHMqNm"
      },
      "source": [
        "The code for the different kinds of loggers is available in the [main/salina/logger.py file](https://github.com/facebookresearch/salina/blob/main/salina/logger.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c872tM4WM5FH"
      },
      "source": [
        "Having logging provided under the hood is one of the features where using RL libraries like SaLinA will allow you to save time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmsf5BENLz10"
      },
      "source": [
        "`instantiate_class` is an inner SaLinA mechanism. The `instantiate_class`function is available in the [main/salina/__init__.py file](https://github.com/facebookresearch/salina/blob/main/salina/__init__.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOkauz_0H2GA"
      },
      "outputs": [],
      "source": [
        "class Logger():\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    self.logger = instantiate_class(cfg.logger)\n",
        "\n",
        "  def add_log(self, log_string, loss, epoch):\n",
        "    self.logger.add_scalar(log_string, loss.item(), epoch)\n",
        "\n",
        "  # Log losses\n",
        "  def log_losses(self, cfg, epoch, critic_loss, entropy_loss, a2c_loss):\n",
        "    self.add_log(\"critic_loss\", critic_loss, epoch)\n",
        "    self.add_log(\"entropy_loss\", entropy_loss, epoch)\n",
        "    self.add_log(\"a2c_loss\", a2c_loss, epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2vq1OJHWCIE"
      },
      "source": [
        "### Setup the optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzmEKF4J8qjg"
      },
      "source": [
        "We use a single optimizer to tune the parameters of the actor (in the prob_agent part) and the critic (in the critic_agent part). It would be possible to have two optimizers which would work separately on the parameters of each component agent, but it would be more complicated because updating the actor requires the gradient of the critic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFfzXEu2WFWj"
      },
      "outputs": [],
      "source": [
        "# Configure the optimizer over the a2c agent\n",
        "def setup_optimizers(cfg, prob_agent, critic_agent):\n",
        "  optimizer_args = get_arguments(cfg.algorithm.optimizer)\n",
        "  parameters = nn.Sequential(prob_agent, critic_agent).parameters()\n",
        "  optimizer = get_class(cfg.algorithm.optimizer)(parameters, **optimizer_args)\n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6SuPOdW_hxl"
      },
      "source": [
        "### Execute agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqlH-8DaVWx2"
      },
      "source": [
        "This is the tricky part with SaLinA, the one we need to understand in detail. The difficulty lies in the copy of the last step and the way to deal with the n_steps return."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWAmm0pPotTC"
      },
      "source": [
        "The call to `agent(workspace, t=1, n_steps=cfg.algorithm.n_timesteps - 1, stochastic=True)` makes the agent run a number of steps in the workspace. In practice, it calls [this function](https://github.com/facebookresearch/salina/blob/47bea8b980ca3ce2461ada82a94c2e4cc59f125d/salina/agent.py#L58) which makes a forward pass of the agent network using the workspace data and updates the workspace accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn3MlNQ3qGPr"
      },
      "source": [
        "Now, if we start at the first epoch (`epoch=0`), we start from the first step (`t=0`). But when subsequently we perform the next epochs (`epoch>0`), there is a risk that we do not cover the transition at the border between the previous epoch and the current epoch. To avoid this risk, we need to shift the time indexes, hence the (`t=1`) and (`cfg.algorithm.n_timesteps - 1`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4wkNJqa_k5c"
      },
      "outputs": [],
      "source": [
        "def execute_agent(cfg, epoch, workspace, agent):\n",
        "  if epoch > 0:\n",
        "      workspace.zero_grad()\n",
        "      workspace.copy_n_last_steps(1)\n",
        "      agent(\n",
        "        workspace, t=1, n_steps=cfg.algorithm.n_timesteps - 1, stochastic=True\n",
        "      )\n",
        "  else:\n",
        "    agent(workspace, t=0, n_steps=cfg.algorithm.n_timesteps, stochastic=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQNvhO_VAJbh"
      },
      "source": [
        "### Compute critic loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxxobbxRaJXO"
      },
      "source": [
        "Note the `critic[1:].detach()` in the computation of the temporal difference target. The idea is that we compute this target as a function of $V(s_{t+1})$, but we do not want to apply gradient descent on this $V(s_{t+1})$, we will only apply gradient descent to the $V(s_t)$ according to this target value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngf5NHvWBbrE"
      },
      "source": [
        "In practice, `x.detach()` detaches a computation graph from a tensor, so it avoids computing a gradient over this tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXwrjbueoDw6"
      },
      "source": [
        "Note also the trick to deal with terminal states. If the state is terminal, $V(s_{t+1})$ does not make sense. Thus we need to ignore this term. So we multiply the term by (1 - done): if done is False (=0), we get the term. If done is true (=1), we are at a terminal state and (1- done) = 0, so we ignore the term. This trick is used in many RL libraries, e.g. SB3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcF-DKr3n3g6"
      },
      "source": [
        "TODO: understand why we convert into float with `.float()` rather than into an integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sepUK-gAM3u"
      },
      "outputs": [],
      "source": [
        "def compute_critic_loss(cfg, reward, done, critic):\n",
        "  # Compute temporal difference\n",
        "  target = reward[1:] + cfg.algorithm.discount_factor * critic[1:].detach() * (1 - done[1:].float())\n",
        "  td = target - critic[:-1]\n",
        "\n",
        "  # Compute critic loss\n",
        "  td_error = td ** 2\n",
        "  critic_loss = td_error.mean()\n",
        "  return critic_loss, td"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4FUSogvA1hx"
      },
      "source": [
        "### Compute A2C loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFJUS-iqA4Me"
      },
      "outputs": [],
      "source": [
        "def compute_a2c_loss(action_probs, action, td):\n",
        "  action_logp = _index(action_probs, action).log()\n",
        "  a2c_loss = action_logp[:-1] * td.detach()\n",
        "  return a2c_loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmi91gANWT4z"
      },
      "source": [
        "## Main training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ixFZeCRN6Y6"
      },
      "source": [
        "Note that everything about the shared workspace between all the agents is completely hidden under the hood. This results in a gain of productivity, at the expense of having to dig into the salina code if you want to understand the details, change the multiprocessing model, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFB1XFE5YEc6"
      },
      "source": [
        "Note that we `optimizer.zero_grad()`, `loss.backward()` and `optimizer.step()` lines. Several things need to be explained here.\n",
        "- `optimizer.zero_grad()` is necessary to cancel all the gradients computed at the previous iterations\n",
        "- note that we sum all the losses, both for the critic and the actor, before applying back-propagation with `loss.backward()`. At first glance, summing these losses may look weird, as the actor and the critic receive different updates with different parts of the loss. This mechanism relies on the central property of tensor manipulation libraries like TensorFlow and pytorch. In pytorch, each loss tensor comes with its own graph of computation for back-propagating the gradient, in such a way that when you back-propagate the loss, the adequate part of the loss is applied to the adequate parameters.\n",
        "These mechanisms are partly explained [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
        "- since the optimizer has been set to work with both the actor and critic parameters, `optimizer.step()` will optimize both agents and pytorch ensure that each will receive its own part of the gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk85_sRWW-5s"
      },
      "outputs": [],
      "source": [
        "def run_a2c(cfg):\n",
        "  # 1)  Build the  logger\n",
        "  logger = Logger(cfg)\n",
        "  \n",
        "  # 2) Create the environment agent\n",
        "  env_agent = EnvAgent(cfg)\n",
        "\n",
        "  # 3) Create the A2C Agent\n",
        "  a2c_agent, prob_agent, critic_agent = create_a2c_agent(cfg, env_agent)\n",
        "\n",
        "  # 4) Create the temporal critic agent to compute critic values over the workspace\n",
        "  tcritic_agent = TemporalAgent(critic_agent)\n",
        "\n",
        "  # 5) Configure the workspace to the right dimension\n",
        "  # Note that no parameter is needed to create the workspace. \n",
        "  # In the training loop, calling the agent() and critic_agent() \n",
        "  # will take the workspace as parameter\n",
        "  workspace = salina.Workspace()\n",
        "\n",
        "  # 6) Configure the optimizer over the a2c agent\n",
        "  optimizer = setup_optimizers(cfg, prob_agent, critic_agent)\n",
        "  \n",
        "  # 7) Training loop\n",
        "  epoch = 0\n",
        "  for epoch in range(cfg.algorithm.max_epochs):\n",
        "    # Execute the agent in the workspace\n",
        "    execute_agent(cfg, epoch, workspace, a2c_agent)\n",
        "\n",
        "    # Compute the critic value over the whole workspace\n",
        "    tcritic_agent(workspace, n_steps=cfg.algorithm.n_timesteps)\n",
        "\n",
        "    # Get relevant tensors (size are timestep x n_envs x ....)\n",
        "    critic, done, action_probs, reward, action = workspace[\n",
        "        \"critic\", \"env/done\", \"action_probs\", \"env/reward\", \"action\"\n",
        "      ]\n",
        "\n",
        "    # Compute critic loss\n",
        "    critic_loss, td = compute_critic_loss(cfg, reward, done, critic)\n",
        "\n",
        "    # Compute entropy loss\n",
        "    entropy_loss = torch.distributions.Categorical(action_probs).entropy().mean()\n",
        "\n",
        "    # Compute A2C loss\n",
        "    a2c_loss = compute_a2c_loss(action_probs, action, td)\n",
        "\n",
        "    # Store the losses for tensorboard display\n",
        "    logger.log_losses(cfg, epoch, critic_loss, entropy_loss, a2c_loss)\n",
        "\n",
        "    # Compute the total loss\n",
        "    loss = (\n",
        "      -cfg.algorithm.entropy_coef * entropy_loss\n",
        "      + cfg.algorithm.critic_coef * critic_loss\n",
        "      - cfg.algorithm.a2c_coef * a2c_loss\n",
        "    )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute the cumulated reward on final_state\n",
        "    creward = workspace[\"env/cumulated_reward\"]\n",
        "    creward = creward[done]\n",
        "    if creward.size()[0] > 0:\n",
        "      logger.add_log(\"reward\", creward.mean(), epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6bc3zzKua_"
      },
      "source": [
        "## Definition of the parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36r4PAfvKx-f"
      },
      "source": [
        "The logger is defined as `salina.logger.TFLogger` so as to use a tensorboard visualisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB2B8zELNWQd"
      },
      "outputs": [],
      "source": [
        "params={\n",
        "  \"logger\":{\n",
        "    \"classname\": \"salina.logger.TFLogger\",\n",
        "    \"log_dir\": \"./tmp\",\n",
        "    \"cache_size\": 10000,\n",
        "    \"every_n_seconds\": 10,\n",
        "    \"verbose\": False,    \n",
        "    },\n",
        "\n",
        "  \"algorithm\":{\n",
        "    \"env_seed\": 432,\n",
        "    \"n_envs\": 8,\n",
        "    \"n_timesteps\": 16,\n",
        "    \"max_epochs\": 10000,\n",
        "    \"discount_factor\": 0.95,\n",
        "    \"entropy_coef\": 0.001,\n",
        "    \"critic_coef\": 1.0,\n",
        "    \"a2c_coef\": 0.1,\n",
        "    \"architecture\":{\"hidden_size\": 32},\n",
        "    \"env\":{\n",
        "      \"classname\": \"__main__.make_env\",\n",
        "      \"env_name\": \"CartPole-v1\",\n",
        "      \"max_episode_steps\": 100,\n",
        "    },\n",
        "    \"optimizer\":\n",
        "    {\n",
        "      \"classname\": \"torch.optim.Adam\",\n",
        "      \"lr\": 0.01,\n",
        "    }\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp7jDeGkaoM1"
      },
      "source": [
        "### Launching tensorboard to visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "l42OUoGROlSt",
        "outputId": "afc5a8c5-8c0f-410c-82d7-25449e008097"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b6d7ae1ccb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_a2c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-31e73bda8c9c>\u001b[0m in \u001b[0;36mrun_a2c\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# 2) Create the environment agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0menv_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# 3) Create the A2C Agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-ebb3df09ed2a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mn_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# TODO: replace the code below by a unique context-sensitive function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/salina/__init__.py\u001b[0m in \u001b[0;36minstantiate_class\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e80636a1d1e7>\u001b[0m in \u001b[0;36mmake_env\u001b[0;34m(env_name, max_episode_steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTimeLimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_enforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_enforcing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderEnforcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mid_requested\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mofficial\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mentry_point\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mentrypoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mreward_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mreward\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mconsidered\u001b[0m \u001b[0msolved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mnondeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0meven\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0msteps\u001b[0m \u001b[0mthat\u001b[0m \u001b[0man\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mconsist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_env_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"Parse environment ID string format.\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mSupportsFloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moverload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartpole\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmountain_car\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMountainCarEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous_mountain_car\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContinuous_MountainCarEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpendulum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPendulumEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macrobot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAcrobotEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m### Description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir ./tmp\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "config=OmegaConf.create(params)\n",
        "run_a2c(config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "A2C_SALINA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
